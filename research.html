<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Fahim Anzum's Website</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="styles.css" rel="stylesheet" />
    </head>
<body>

    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Fahim Anzum</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/Fahim_Profile Picture - Copy.jpg" alt="Fahim's Photo" /></span>
            </a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link" href="research.html">Research</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#experience">Experience</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#awards">Awards</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#certifications">Certifications</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#contact">Contact</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="/CV_Fahim Anzum.pdf" target="_blank">CV</a></li>
                </ul>
            </div>
        </nav>

    <!-- Research Section -->
    <div class="container mt-5">
        <h2 class="mb-5 text-center">Research</h2>

        <!-- Research Theme 1 -->
        <div class="row mb-5">
            <div class="col-lg-4">
                <img src="assets/Hybrid Model Architecture.png" class="img-fluid rounded" alt="Emotion Detection">
            </div>
            <div class="col-lg-8">
                <h3>Interpretable Social Behavior Analaysis</h3>
                <p>While the deep learning models offer rich contextual insights, their blackbox nature limits 
                    interpretability and overlooks user-specific stylistic patterns. In this work, I developed 
                    a novel interpretable handcrafted feature representation to capture users' distinct domain-specific emotional cues 
                    from social media microblogs.
                    By employing genetic algorithmic approach, I extracted and combined three user-specific interpretable features: 
                    <a><strong>Stylistic (S), Sentiment (SE), and Linguistic(L).</strong></a> Furthermore, I extended this work 
                    by fusing the interpretable handcrafted representation with rich and contextual LLM-driven latent deep features.
                    This bi-modal architecture utilizes the complementary strengths of diverse feature groups, improving accuracy, 
                    robustness, and interpretability. This is the first work to combine interpretable handcrafted features with 
                    LLM-driven contextual deep features for bi-modal emotion detection, 
                    laying the groundwork for fostering robust and trustworthy human-machine teaming by 
                    capturing behavioral cues with greater precision.
                </p>
                <p><strong>Related Publications:</strong></p>
                <ul>
                    <li><a href="https://ieeexplore.ieee.org/document/10050864" target="_blank">Emotion Detection from Micro-Blogs (IEEE Access, 2023)</a></li>
                    <li><a href="https://ieeexplore.ieee.org/abstract/document/10555818" target="_blank">EmoBlend Fusion (IEEE ICHMS, 2024) - Best Paper Award</a></li>
                </ul>
            </div>
        </div>

        <!-- Research Theme 2 -->
        <div class="row mb-5">
            <div class="col-lg-4">
                <img src="assets/1-Fig1-v2.jpg" class="img-fluid rounded" alt="Trustworthy AI">
                <p></p>
                <img src="assets/1-Fig2.jpg" class="img-fluid rounded" alt="Trustworthy AI">
            </div>
            <div class="col-lg-8">
                <h3>Trust, Fairness, and Explainability in AI</h3>
                <p>
                    My research investigates trust, fairness, bias, and explainability in AI-driven social media data mining. 
                    It highlights how biases in data preparation, processing, and modeling distort AI predictions, 
                    leading to unfair outcomes and eroding user trust. To address these challenges, 
                    I proposed three mitigation strategies: curating diverse datasets, 
                    implementing transparency-focused datasheets, and incorporating qualitative analysis for bias detection. 
                    These efforts promote fairness and accountability, ensuring AI systems are more transparent and ethical 
                    in social media applications.
                </p>

                <p>
                    I developed a Trustworthy AI (TXAI) framework that integrates affective traits, 
                    personality, and social influences for ethical AI decision-making. 
                    This framework employs a weighted trust assessment mechanism and emphasizes ethical data practices, 
                    robust bias mitigation, and explainability. Collaborating with interdisciplinary teams, 
                    I explored governance, regulatory compliance, and transparency across AI workflows. 
                    My research improves bias detection through multi-source data analysis and iterative evaluation, 
                    producing actionable guidelines for responsible AI deployment. This work supports user-centered AI, 
                    aligning AI technologies with societal values to ensure fairness, privacy, and trustworthiness.                </p>
                <p><strong>Related Publications:</strong></p>
                <ul>
                    <li><a href="https://ieeexplore.ieee.org/abstract/document/9937358" target="_blank">Biases, Fairness, and Implications of Using AI in Social Media Data Mining
                        (IEEE Cyberworlds, 2022)</a></li>
                    <li><a href="https://arxiv.org/abs/2408.15550" target="_blank">Trustworthy and Responsible AI for Human-Centric Autonomous Decision-Making Systems
                        (Preprint, 2024)</a></li>
                    <li><a href="https://link.springer.com/chapter/10.1007/978-3-031-10706-1_14" target="_blank">A Multifaceted Role of Biometrics in Online Security, Privacy, and Trustworthy Decision Making (Springer Nature, 2022)</a></li>

                </ul>
            </div>
        </div>

        <!-- Research Theme 3 -->
        <div class="row mb-5">
            <div class="col-lg-4">
                <img src="assets/lighthouse.png" class="img-fluid rounded" alt="XAI for Mental Health and Well-being">
            </div>
            <div class="col-lg-8">
                <h3>XAI for Mental Health and Well-being</h3>
                <p>My research explores Canadians' perception of trust in AI for healthcare, 
                    using LLM-driven opinion mining to uncover public concerns and trust factors. 
                    Additionally, my ongoing research investigates how users' emotional, personality, and linguistic attributes
                    extracted from social media mental health discussions, can be leveraged to 
                    identify diverse root causes of mental health issues and develop XAI framework to provide personalized 
                    and transparent policy recommendations. This work aims to bridge AI and psychology for ethical, 
                    explainable, and user-centered mental health support.</p>
                <p><strong>Related Publications:</strong></p>
                <ul>
                    <li>A Digital Lighthouse: Exploring Health Concerns and Public
                        Trust Using LLM-Driven Opinion Mining from Canadian
                        Reddit Communities (Under Review, PLOS One, 2024)</a></li>
                </ul>
            </div>
        </div>

        
    </div>

    <!-- Bootstrap and jQuery -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>

<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Fahim Anzum | Research</title>
  <link rel="icon" href="assets/img/favicon.ico">
  <link rel="stylesheet" href="css/style.css">
</head>
<body>
<header>
  <div class="container">
    <div class="navbar">
      <a class="brand" href="index.html">Fahim Anzum</a>


      <div class="controls">
  <button class="themebtn" id="themeBtn" type="button">Dark</button>
  <button class="mobile" id="menuBtn" aria-label="Menu">Menu</button>
</div>

      <nav class="navlinks" id="navLinks" aria-label="Primary navigation">
        <a data-nav href="index.html">Home</a>
        <a data-nav href="research.html">Research</a>
        <a data-nav href="publications.html">Publications</a>
        <a data-nav href="experience.html">Experience</a>
        <!-- <a href="CV_Fahim Anzum_Research_Latest.pdf" target="_blank" rel="noopener">CV</a> -->
      </nav>
    </div>
  </div>
</header>

<main class="container">
  <!-- <section class="section">
    <div class="card">
      <div class="h1">Research</div>
      <p>To learn more about my research and intended future direction, please See my <a href="https://btlabuofc.wixsite.com/btlab" target="_blank" rel="noopener">
  Research Statement</a> for more details</p>
    </div>
  </section> -->

  <section class="section rblock">
  <!-- <h2 class="rtitle">Interpretable Social Behavior Analysis</h2> -->
  <div class="rhead">
  <h2 class="rhead-title">Interpretable Social Behavior Analysis</h2>
  <div class="rhead-rule"></div>
</div>


  <div class="rtwo">
    <!-- LEFT: overview card -->
    <div class="rcard">
      <p class="rtext">
        While the deep learning models offer rich contextual insights, their blackbox nature limits 
        interpretability and overlooks user-specific stylistic patterns. I developed 
        a novel interpretable handcrafted feature representation to capture users' distinct domain-specific emotional cues 
        from social media microblogs. By employing genetic algorithmic approach, I extracted and combined three user-specific interpretable features: 
                    <a><strong>Stylistic (S), Sentiment (SE), and Linguistic(L).</strong></a> Furthermore, I extended this work 
                    by fusing the interpretable handcrafted representation with rich and contextual LLM-driven latent deep features.
                    This bi-modal architecture utilizes the complementary strengths of diverse feature groups, improving accuracy and interpretability.
      </p>

      <div class="rsubtitle">Relevant publications</div>
      <ul class="rlist">
        <li>
          <a href="https://ieeexplore.ieee.org/document/10050864" target="_blank" rel="noopener">
            Emotion Detection From Micro-Blogs Using Novel Input Representation
          </a>
          <span class="rmeta">IEEE Access, 2023</span>
        </li>
        <li>
          <a href="https://ieeexplore.ieee.org/abstract/document/10555818" target="_blank" rel="noopener">
            EmoBlend Fusion: Leveraging Handcrafted and Deep Features for Emotion Detection
          </a>
          <span class="rmeta">IEEE ICHMS, 2024 · Best Paper</span>
        </li>
      </ul>
    </div>

    <!-- RIGHT: image switcher -->
    <div class="rmedia" data-gallery>
      <button class="rnav prev" type="button" aria-label="Previous image">‹</button>

      <div class="rframe tall">
        <img class="rimg active" src="assets/img/research/SSEL.png" alt="EmoBlend overview figure">
        <img class="rimg" src="assets/img/research/emoblend.png" alt="Feature fusion diagram">
      </div>

      <button class="rnav next" type="button" aria-label="Next image">›</button>

      <div class="rdots" aria-label="Image selector"></div>
    </div>
  </div>
</section>


  <section class="section rblock">
    <div class="rhead">
  <h2 class="rhead-title">Trustworthy and Explainable AI</h2>
  <div class="rhead-rule"></div>
</div>
  <!-- <h2 class="rtitle">Trustworthy and Explainable AI</h2> -->

  <div class="rtwo">
    <!-- LEFT: overview card -->
    <div class="rcard">
      <p class="rtext">
        I examined trust, fairness, bias, and explainability in AI-driven social media data mining, 
        with a focus on how biases introduced during data curation, processing, and modeling distort predictions
         and undermine user trust. I proposed mitigation strategies centered on diverse data curation, 
         transparency-oriented datasheets, and qualitative bias analysis. Building on this work, 
         I developed a Trustworthy AI (TXAI) framework that integrates affective, personality, and social signals 
         through a weighted trust assessment mechanism to support ethical and explainable decision-making. 
         Through interdisciplinary collaboration, my research advances practical guidelines for responsible AI
          deployment, governance, and bias-aware evaluation across AI workflows. </p>

      <div class="rsubtitle">Relevant publications</div>
      <ul class="rlist">
        <li>
          <a href="https://arxiv.org/abs/2408.15550" target="_blank" rel="noopener">
            Trustworthy and Responsible AI for Human-Centric Autonomous Decision-Making Systems
          </a>
          <span class="rmeta">TMLR, 2025</span>
        </li>

        <li>
          <a href="https://aisel.aisnet.org/amcis2025/intelfuture/intelfuture/46/" target="_blank" rel="noopener">
            FairHealthGrid: A Systematic Framework for Evaluating Bias Mitigation Strategies in Healthcare Machine Learning
          </a>
          <span class="rmeta">AMCIS, 2025</span>
        </li>

        <li>
          <a href="https://www.igi-global.com/chapter/a-comprehensive-review-of-trustworthy-ethical-and-explainable-computer-vision-advancements-in-online-social-media/348346" target="_blank" rel="noopener">
            A Comprehensive Review of Trustworthy, Ethical, and Explainable Computer Vision Advancements in Online Social Media
          </a>
          <span class="rmeta">IGI Global, 2024</span>
        </li>
        
        <li>
          <a href="https://ieeexplore.ieee.org/abstract/document/9937358" target="_blank" rel="noopener">
            Biases, Fairness, and Implications of Using AI in Social Media Data Mining
          </a>
          <span class="rmeta">IEEE CW, 2022</span>
        </li>
        

        <li>
          <a href="https://link.springer.com/chapter/10.1007/978-3-031-10706-1_14" target="_blank" rel="noopener">
            A Multifaceted Role of Biometrics in Online Security, Privacy, and Trustworthy Decision Making
          </a>
          <span class="rmeta">Springer Nature Link, 2022</span>
        </li>
      </ul>
    </div>

    <!-- RIGHT: image switcher -->
    <div class="rmedia" data-gallery>
      <button class="rnav prev" type="button" aria-label="Previous image">‹</button>

      <div class="rframe tall">
        <img class="rimg active" src="assets/img/research/1-Fig2.jpg" alt="EmoBlend overview figure">
        <img class="rimg" src="assets/img/research/1-Fig1-v2.jpg" alt="Feature fusion diagram">
      </div>

      <button class="rnav next" type="button" aria-label="Next image">›</button>

      <div class="rdots" aria-label="Image selector"></div>
    </div>
  </div>
</section>


  <section class="section rblock">
  <!-- <h2 class="rtitle">XAI for Mental Health and Well-being</h2> -->
  <div class="rhead">
  <h2 class="rhead-title">XAI for Mental Health and Well-being</h2>
  <div class="rhead-rule"></div>
</div>

  <div class="rtwo">
    <!-- LEFT: overview card -->
    <div class="rcard">
      <p class="rtext">
        My research explores Canadians' perception of trust in AI for healthcare, 
        using LLM-driven opinion mining to uncover public concerns and trust factors. 
        Additionally, my ongoing research investigates how users' emotional, personality, 
        and linguistic attributes extracted from social media mental health discussions, 
        can be leveraged to identify diverse root causes of mental health issues and develop 
        XAI framework to provide personalized and transparent policy recommendations. 
        This work aims to bridge AI and psychology for ethical, explainable, and user-centered mental health support.  </p>

      <div class="rsubtitle">Relevant publications</div>
      <ul class="rlist">
        <li>
          <a href="https://link.springer.com/chapter/10.1007/978-3-032-02406-0_5" target="_blank" rel="noopener">
            Exploring Public Trust Through LLM-Driven Opinion Mining
          </a>
          <span class="rmeta">CISIM, 2025</span>
        </li>

        
      </ul>
    </div>

    <!-- RIGHT: image switcher -->
    <div class="rmedia" data-gallery>
      <button class="rnav prev" type="button" aria-label="Previous image">‹</button>

      <div class="rframe compact">
        <img class="rimg active" src="assets/img/research/lighthouse.png" alt="EmoBlend overview figure">
      </div>

      <button class="rnav next" type="button" aria-label="Next image">›</button>

      <div class="rdots" aria-label="Image selector"></div>
    </div>
  </div>
</section>

  


  <div class="footer">© <span id="year"></span> Fahim Anzum</div>
</main>

<script src="js/main.js"></script>
</body>
</html>
